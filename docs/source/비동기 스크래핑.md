# 비동기 스크래핑

> Python에서 asyncio를 사용해 비동기 스크래핑을 했을 경우 어느정도의 속도 변화가 있는지를 알아봅니다.



구글에서 99개의 식료품에 대한 이미지를 스크래핑하여 데이터베이스에 저장합니다.

사용 기술

- Python
- Django
- MySql



### 동기

```python
def get_google_image(search_text: str):
    search_text = search_text
    url         = f'https://www.google.com/search?q={search_text}&tbm=isch'
    soup        = requesting(url)
    image       = soup.find("img", {"class": "yWs4tf"}).get('src')
    return image
```

이미지 하나를 불러오는 함수입니다.



음식 99개의 데이터가 담긴 food table을 채우기 위해 다음과 같은 코드조각을 사용합니다.

```python
def init_food(self):
    start = timeit.default_timer()

    for item_code, food in zip(kind_code_form['품목 코드'],
                                kind_code_form['품목명']):
        item_category = item_code // 100 * 100
        if Food.objects.filter(item_code=item_code):
            continue
    
        image = get_google_image(food)
        serializer = FoodSerializer(data={'item_code': item_code,
                                          'item_category': item_category,
                                          'food': food,
                                          'image': image})
        if serializer.is_valid(raise_exception=True):
            serializer.save()
    duration = timeit.default_timer() - start
    print('Total Running Time:', duration)
```



테스트 결과:

```
Total Running Time: 48.32085003494285
```



### 비동기

다음은 비동기식 이미지 스크래핑 코드조각입니다.

본 코드는 `image`, `kamis` 두 가지 모드가 있으나, 여기서는 `image`에 대해서만 설명합니다.

```python
class Scrap:

    def __init__(self):
        self.loop = asyncio.new_event_loop()
        self.url = None

    async def fetch(self, mode, executor, url, parser='html.parser'):
        """
        image: google에서 검색한 이미지를 가져옵니다.
        """

        res = await self.loop.run_in_executor(executor, requests.get, url)
        if res.status_code != 200:
            return None

        if mode == 'image':
            soup    = BeautifulSoup(res.content, parser)
            image   = soup.find("img", {"class": "yWs4tf"}).get('src')
            return image

    async def main(self, mode, urls):
        executor = ThreadPoolExecutor(max_workers=100)
        with ThreadPoolExecutor(max_workers=100) as executor:
            futures = (asyncio.ensure_future(self.fetch(mode, executor, url)) for url in urls)
            result = await asyncio.gather(*futures)
        return result

    def get_google_images(self, search_texts):
        urls = [f'https://www.google.com/search?q={search_text}&tbm=isch' for search_text in search_texts]
        result = self.loop.run_until_complete(self.main(mode='image', urls=urls))
        return result
```



```python
def init_food(self):
    start = timeit.default_timer()
    foods   = [food for food in self.kind_code_form['품목명']]
    scrap   = Scrap()
    images  = scrap.get_google_images(foods)

    for idx, item_code in enumerate(self.kind_code_form['품목 코드']):
        item_category = item_code // 100 * 100
        if Food.objects.filter(item_code=item_code):
            continue
            
        serializer = FoodSerializer(data={'item_code': item_code,
                                            'item_category': item_category,
                                            'food': foods[idx],
                                            'image': images[idx]})
        if serializer.is_valid(raise_exception=True):
            serializer.save()
    duration = timeit.default_timer() - start
    print('Total Running Time:', duration)
```



테스트 결과:

```
Total Running Time: 6.566416112007573
```



약 7~8배 정도의 속도 향상을 확인할 수 있습니다.

